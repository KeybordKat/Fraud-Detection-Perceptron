{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e9df25",
   "metadata": {},
   "source": [
    "# Fraud Detection with Perceptron\n",
    "This notebook demonstrates how to build a **cost-sensitive Perceptron model** for fraud detection using imbalanced transaction data.\n",
    "\n",
    "We will:\n",
    "1. Import necessary libraries\n",
    "2. Define Perceptron training/prediction functions\n",
    "3. Load and preprocess transaction data\n",
    "4. Handle class imbalance with SMOTE\n",
    "5. Train and evaluate the model\n",
    "6. Explore precision-recall trade-offs\n",
    "7. Build an inference helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6732bc4",
   "metadata": {},
   "source": [
    "## Perceptron Functions\n",
    "We define a **custom cost-sensitive Perceptron**:\n",
    "- The `perceptron_train` function updates weights differently for fraud cases (higher penalty).\n",
    "- Training accuracy is tracked across epochs.\n",
    "- The `perceptron_predict` function applies the learned weights to classify new samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b817c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perceptron_train(x_matrix, y, T, fraud_weight=10):\n",
    "    theta = np.zeros(x_matrix.shape[1])\n",
    "    theta_zero = 0\n",
    "    accuracy_history = []\n",
    "\n",
    "    for _ in range(T):\n",
    "        for i in range(x_matrix.shape[0]):\n",
    "            if y[i] * (np.dot(theta, x_matrix[i]) + theta_zero) <= 0:\n",
    "                update = y[i] * (fraud_weight if y[i] == 1 else 1)\n",
    "                theta = theta + update * x_matrix[i]\n",
    "                theta_zero = theta_zero + update\n",
    "        y_pred_train = np.where(np.dot(x_matrix, theta) + theta_zero >= 0, 1, -1)\n",
    "        accuracy_history.append(np.mean(y_pred_train == y))\n",
    "\n",
    "    return theta, theta_zero, accuracy_history\n",
    "\n",
    "\n",
    "def perceptron_predict(x_matrix, theta, theta_zero):\n",
    "    return np.where(np.dot(x_matrix, theta) + theta_zero >= 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef7b23",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore Data\n",
    "We load transaction data from CSV, then perform **feature engineering** to extract additional signals such as balance changes and ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"data/transactions.csv\")\n",
    "\n",
    "df['balance_change'] = df['newbalanceOrig'] - df['oldbalanceOrg']\n",
    "df['dest_balance_change'] = df['newbalanceDest'] - df['oldbalanceDest']\n",
    "df['amount_to_oldbalance_ratio'] = df['amount'] / (df['oldbalanceOrg'] + 1)\n",
    "df['amount_to_newbalance_ratio'] = df['amount'] / (df['newbalanceOrig'] + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2260937",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Features and Target\n",
    "- Features = all transaction attributes (numeric + categorical)\n",
    "- Target = `isFraud` (converted to +1 for fraud, -1 for legit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_df = df.drop(\"isFraud\", axis=1)\n",
    "y = np.where(df[\"isFraud\"].values == 1, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855085b",
   "metadata": {},
   "source": [
    "## Step 3: Preprocessing\n",
    "We apply:\n",
    "- **StandardScaler** for numeric features\n",
    "- **OneHotEncoder** for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7aa27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_features = [\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\",\n",
    "                    \"oldbalanceDest\", \"newbalanceDest\",\n",
    "                    \"balance_change\", \"dest_balance_change\",\n",
    "                    \"amount_to_oldbalance_ratio\", \"amount_to_newbalance_ratio\"]\n",
    "\n",
    "categorical_features = [\"type\"]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "])\n",
    "\n",
    "X = preprocessor.fit_transform(X_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bbb8c9",
   "metadata": {},
   "source": [
    "## Step 4: Train-Test Split\n",
    "We split the dataset into training (70%) and testing (30%), stratified on fraud labels to maintain distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc938ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=(y == 1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d588d",
   "metadata": {},
   "source": [
    "## Step 5: Handle Class Imbalance with SMOTE\n",
    "Fraudulent transactions are rare, so we apply **SMOTE** (Synthetic Minority Oversampling Technique) to balance the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", np.bincount(y_train + 1))\n",
    "print(\"After SMOTE:\", np.bincount(y_train_res + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c69d60",
   "metadata": {},
   "source": [
    "## Step 6: Train Perceptron\n",
    "We train for `T=40` epochs and record training accuracy. The learning process is visualized with a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c91bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T = 40\n",
    "theta, theta_zero, acc_history = perceptron_train(X_train_res, y_train_res, T)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, T + 1), acc_history, marker='o')\n",
    "plt.title(\"Perceptron Training Accuracy Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44afcc",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate Model with Precision-Recall Trade-offs\n",
    "- We compute decision scores for the test set.\n",
    "- We generate a precision-recall curve.\n",
    "- We select the best threshold that maintains high recall (â‰¥ 0.98).\n",
    "- Finally, we evaluate with a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00772319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = np.dot(X_test, theta) + theta_zero\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, scores)\n",
    "\n",
    "target_recall = 0.98\n",
    "best_thresh = 0\n",
    "best_acc = 0\n",
    "for p, r, t in zip(precision, recall, thresholds):\n",
    "    if r >= target_recall:\n",
    "        y_pred_temp = np.where(scores >= t, 1, -1)\n",
    "        acc = np.mean(y_pred_temp == y_test)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_thresh = t\n",
    "\n",
    "print(f\"Best threshold keeping recall={target_recall}: {best_thresh:.4f}, Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "y_pred = np.where(scores >= best_thresh, 1, -1)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Legit (-1)\", \"Fraud (+1)\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620caaf8",
   "metadata": {},
   "source": [
    "## Step 8: Inference Helper\n",
    "We wrap the trained pipeline into a helper function to classify new transactions conveniently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a80c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flag_transaction(tx_dict, preprocessor, theta, theta_zero):\n",
    "    tx_df = pd.DataFrame([tx_dict])\n",
    "    X_tx = preprocessor.transform(tx_df).toarray()\n",
    "    return \"FRAUD\" if perceptron_predict(X_tx, theta, theta_zero)[0] == 1 else \"LEGIT\"\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}